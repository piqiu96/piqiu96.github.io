[{"categories":["成长日记"],"content":"一、回顾 当我准备写年度总结的时候，我大脑是空白的，感觉做了很多事情又感觉什么都没做，所以先回顾下今年都干了什么？ 1-2月：参与2021春节拜年红包项目负责投放机制设计落地，超预期达成目标，项目ROI\u003e2 3月：春季晋升大窗口，晋升失败\u0026调薪，给出理由是缺乏影响力，不太有说服力 4-6月： 搜索运营会场机制重构：担任主力开发成功将项目落地 儿童节商业项目：担任前台负责人做项目设计落地\u0026稳定性，成功保障项目如期交付 外公去世，那段时间心态比较崩 出去放空自己，成都\u0026青海游 7-9月： 持续优化搜索运营会场机制，优化体验\u0026稳定性问题，将架构机制流量推全，支持全新业务场景 秋季晋升小窗口（总监提名），晋升失败，没有问理由，心态已跌到谷底，个人总结反思 出去放空自己，内蒙自驾游 10月-12月： 将户口迁移到成都 KV数据平台重构，担任前台负责人做项目设计落地 投入大量时间系统学习总结 仔细一看，做了很多事情投入了很多精力到工作，过程比较充实，但结果是不满意的。 ","date":"2022-01-05","objectID":"/summary2021/:1:0","tags":null,"title":"2021年度总结：接纳自己，永不服输","uri":"/summary2021/"},{"categories":["成长日记"],"content":"二、目标 当然，过程归过程，还是根据年初设定的目标进行复盘总结。我的目标依然是三个目标，分别对应习惯、工作、生活三个维度。 目标1：持续改进微习惯，将习惯深入我心 （✅完成） 该目标的核心指标分别为运动（2次/周）、早睡早起（4次/周）、手机时长（3小时/天），个人身体指标还是非常的健康，包括睡眠饮食等都控制的不错。 唯一控制不好的就是手机时长，可能还是独处时间太长了，周一到周五三点一线，周六周天除了踢球滑雪游泳剩下就是在家宅着看看书玩玩游戏，喜欢去网络世界去发现什么。解决该问题核心还是脱单和适当社交，建立生活秩序和烟火气，独处久了灵魂总是在你身边飘啊飘影响思绪。 目标2： 加速学习工作节奏，专业知识系统化 （❌没完成） 该目标的核心指标分别为薪资、晋升、知识体系化。该目标肯定是没完成的，甚至可以说是很惨淡。 这三个指标中，我最关注的是晋升 + 知识体系化。薪资和晋升就不用说了，职级和薪资都是对人才认可的一种方式，当这些都不符合你预期的时候，就应该多思考：是自己能力不行？方向不对做的事没成果？领导管理方式不公正？公司大环境不行？ 对于已成定局的东西，我还是秉承不抱怨不气馁，将核心聚焦到改变自己身上，提升能力适应规则适应变化，要么忍要么滚。 对于知识体系化，这个事情是我最想做好也是最有挑战性的。因为工作有3年了，做项目难度和压力上来说会降低很多，但是会面临个问题就是很多东西会做也能拿到结果，但是你讲不清楚也没有方法依据，那么当独立从0到1负责做技术方向时，就会知识沉淀和缺少思考。 目标3：提升生活时间分配，规划定居城市 （❌没完成） 该目标的核心指标分别为脱单、规划定居城市。该目标只是完成一半，脱单依旧没有完成，户口已迁移成都。 其实，脱单说起来难也不难，不难的点在于个人综合素质ok，不算内向兴趣爱好也比较广泛，也接触过很多女生玩得比较开，当然核心要点还是思想未解放，有一点点理想主义，总是觉得脱单优先级不高, 自己现在玩的比较欢脱。 个人认为，三观正、有良好习惯和能力、愿意一起成长，其他都不是问题。 假设不会打扮想弄得好看点，可以报班学化妆健身甚至医美，学习穿搭；假设讨厌家务，可以试着学习做饭，买足够智能化工具降低家务成本；在我的理念里，从来就不是坐享其成拥有奢华的东西，而是享受自己奋斗的过程和所遇到的人与事所带来的珍贵回忆，特别是会感恩在你遇到瓶颈站在你身边的人。 ","date":"2022-01-05","objectID":"/summary2021/:2:0","tags":null,"title":"2021年度总结：接纳自己，永不服输","uri":"/summary2021/"},{"categories":["成长日记"],"content":"三、总结 做得好的地方：身体健康管理非常好 需改进的地方：学习亲密关系，明年争取更进一步 做得不好的地方：知识体系化加大时间投入，再难也要逼自己做 ","date":"2022-01-05","objectID":"/summary2021/:3:0","tags":null,"title":"2021年度总结：接纳自己，永不服输","uri":"/summary2021/"},{"categories":["工程实践"],"content":"#如何做系统稳定性？ ","date":"2022-01-04","objectID":"/stable-system/:0:0","tags":null,"title":"如何做系统稳定性？","uri":"/stable-system/"},{"categories":["工程实践"],"content":"一、稳定性定义 ","date":"2022-01-04","objectID":"/stable-system/:1:0","tags":null,"title":"如何做系统稳定性？","uri":"/stable-system/"},{"categories":["工程实践"],"content":"二、稳定性分析 ","date":"2022-01-04","objectID":"/stable-system/:2:0","tags":null,"title":"如何做系统稳定性？","uri":"/stable-system/"},{"categories":["工程实践"],"content":"三、稳定性思路 预防-发现-止损-定位-复盘 ","date":"2022-01-04","objectID":"/stable-system/:3:0","tags":null,"title":"如何做系统稳定性？","uri":"/stable-system/"},{"categories":["工程实践"],"content":"四、稳定性实践 ","date":"2022-01-04","objectID":"/stable-system/:4:0","tags":null,"title":"如何做系统稳定性？","uri":"/stable-system/"},{"categories":["MySQL"],"content":"MySQL索引 ","date":"2022-01-04","objectID":"/mysql-index/:0:0","tags":null,"title":"MySQL索引","uri":"/mysql-index/"},{"categories":["MySQL"],"content":"一、索引结构 hash：读性能（等值查询高、范围查询低） 有序数组：读性能（等值查询高，范围查询高「二分」）、写性能（元素后移性能降低） -\u003e 适合只读不写场景 二叉搜索树：读写性能高，平衡树有树高问题（读写磁盘有IO瓶颈） -\u003e N叉树 跳表： B+树： 不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。 ","date":"2022-01-04","objectID":"/mysql-index/:1:0","tags":null,"title":"MySQL索引","uri":"/mysql-index/"},{"categories":["MySQL"],"content":"二、索引类型 聚簇索引：主键索引，存储\u003c主键， 行记录\u003e 非聚簇索引：普通索引，存储\u003c索引列，主键\u003e 回表：先查非聚簇索引，然后查聚簇索引，这种行为称为回表 前缀索引： 覆盖索引：查询聚簇索引，假设已满足查询需求，则无需回表。该行为称为覆盖索引 索引下推： ​ 无索引下推：查ID，回表，比较内容 ​ 有索引下推：查ID，匹配所有索引项，再回表比较内容 最左前缀原则： ","date":"2022-01-04","objectID":"/mysql-index/:2:0","tags":null,"title":"MySQL索引","uri":"/mysql-index/"},{"categories":["MySQL"],"content":"索引优化 问题1：前缀匹配 SQL1：select * from t where title = “%xxx%” =\u003e 非前缀匹配 SQL2: select * from where title = “xxx%” =\u003e 前缀匹配 问题2：关联查询 全连接 左连接 ","date":"2022-01-04","objectID":"/mysql-index/:3:0","tags":null,"title":"MySQL索引","uri":"/mysql-index/"},{"categories":["MySQL"],"content":"资料参考 https://mp.weixin.qq.com/s/pQsB_jLb-Qr59aYNk0-SJQ https://mp.weixin.qq.com/s/ap9tkaEuWDi39u0NFxnACA https://blog.csdn.net/qq_26545305/article/details/107962298 https://segmentfault.com/a/1190000038749020 https://www.cnblogs.com/vincently/p/4526560.html ","date":"2022-01-04","objectID":"/mysql-index/:4:0","tags":null,"title":"MySQL索引","uri":"/mysql-index/"},{"categories":["MySQL"],"content":"SQL优化 Sql执行顺序 (8) SELECT(9) DISTINCT column,… 选择字段 、去重 (6) AGG_FUNC(column or expression),… 聚合函数 (1) FROM [left_table] 选择表 (3) \u003cjoin_type\u003e JOIN \u003cright_table\u003e 链接 (2) ON \u003cjoin_condition\u003e 链接条件 (4) WHERE \u003cwhere_condition\u003e 条件过滤 (5) GROUP BY \u003cgroup_by_list\u003e 分组 (7) HAVING \u003chaving_condition\u003e 分组过滤 (10) ORDER BY \u003corder_by_list\u003e 排序 (11) LIMIT count OFFSET count; 分页 基础Sql优化 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:0:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"查询SQL尽量不要使用select *，而是具体字段 反例： SELECT * FROM student 正例： SELECT id,NAME FROM student 理由： 字段多时，大表能达到100多个字段甚至达200多个字段 只取需要的字段，节省资源、减少网络开销 select * 进行查询时，很可能不会用到索引，就会造成全表扫描 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:1:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"避免在where子句中使用or来连接条件 查询id为1或者薪水为3000的用户： 反例： SELECT * FROM student WHERE id=1 OR salary=30000 正例： 使用union all SELECT * FROM student WHERE id=1 UNION ALL SELECT * FROM student WHERE salary=30000 分开两条sql写 SELECT * FROM student WHERE id=1 SELECT * FROM student WHERE salary=30000 理由： 使用or可能会使索引失效，从而全表扫描 对于or没有索引的salary这种情况，假设它走了id的索引，但是走到salary查询条件时，它还得全表扫描。也就是说整个过程需要三步：全表扫描+索引扫描+合并。如果它一开始就走全表扫描，直接一遍扫描就搞定。虽然mysql是有优化器的，处于效率与成本考虑，遇到or条件，索引还是可能失效的 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:2:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"使用varchar代替char 反例： deptname char(100) DEFAULT NULL COMMENT ‘部门名称’ 正例： deptname varchar(100) DEFAULT NULL COMMENT ‘部门名称’ 理由： varchar变长字段按数据内容实际长度存储，存储空间小，可以节省存储空间 char按声明大小存储，不足补空格 其次对于查询来说，在一个相对较小的字段内搜索，效率更高 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:3:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"尽量使用数值替代字符串类型 主键（id）：primary key优先使用数值类型int，tinyint 性别（sex）：0-代表女，1-代表男；数据库没有布尔类型，mysql推荐使用tinyint 支付方式（payment）：1-现金、2-微信、3-支付宝、4-信用卡、5-银行卡 服务状态（state）：1-开启、2-暂停、3-停止 商品状态（state）：1-上架、2-下架、3-删除 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:5:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"查询尽量避免返回大量数据 如果查询返回数据量很大，就会造成查询时间过长，网络传输时间过长。同时，大量数据返回也可能没有实际意义。如返回上千条甚至更多，用户也看不过来。 通常采用分页，一页习惯10/20/50/100条。 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:6:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"使用explain分析你SQL执行计划 SQL很灵活，一个需求可以很多实现，那哪个最优呢？SQL提供了explain关键字，它可以分析你的SQL执行计划，看它是否最佳。Explain主要看SQL是否使用了索引。 EXPLAIN SELECT * FROM student WHERE id=1 返回结果： ","date":"2022-01-04","objectID":"/mysql-sqlbest/:7:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"是否使用了索引及其扫描类型 SQL索引概念（详解B+树） type： ALL 全表扫描，没有优化，最慢的方式 index 索引全扫描 range 索引范围扫描，常用语\u003c，\u003c=，\u003e=，between等操作 ref 使用非唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中 eq_ref 类似ref，区别在于使用的是唯一索引，使用主键的关联查询 const 当查询是对主键或者唯一键进行精确查询，系统会把匹配行中的其他列作为常数处理 null MySQL 不访问任何表或索引，直接返回结果 System 表只有一条记录(实际中基本不存在这个情况) 性能排行： System \u003e const \u003e eq_ref \u003e ref \u003e range \u003e index \u003e ALL possible_keys： 显示可能应用在这张表中的索引 key： 真正使用的索引方式 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:8:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"创建name字段的索引 提高查询速度的最简单最佳的方式 ALTER TABLE student ADD INDEX index_name (NAME) ","date":"2022-01-04","objectID":"/mysql-sqlbest/:9:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"优化like语句： 模糊查询，程序员最喜欢的就是使用like，但是like很可能让你的索引失效 反例： 反例： EXPLAIN SELECT id,NAME FROM student WHERE NAME LIKE ‘%1’ EXPLAIN SELECT id,NAME FROM student WHERE NAME LIKE ‘%1%’ 正例： EXPLAIN SELECT id,NAME FROM student WHERE NAME LIKE ‘1%’ 理由： 未使用索引：故意使用sex非索引字段 EXPLAIN SELECT id,NAME FROM student WHERE NAME=1 OR sex=1 主键索引生效 EXPLAIN SELECT id,NAME FROM student WHERE id=1 索引失效，type=ALL，全表扫描 EXPLAIN SELECT id,NAME FROM student WHERE id LIKE ‘%1’ ","date":"2022-01-04","objectID":"/mysql-sqlbest/:10:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"字符串怪现象 反例： #未使用索引 EXPLAIN SELECT * FROM student WHERE NAME=123 正例： #使用索引 EXPLAIN SELECT * FROM student WHERE NAME=‘123’ 理由： 为什么第一条语句未加单引号就不走索引了呢？这是因为不加单引号时，是字符串跟数字的比较，它们类型不匹配，MySQL会做隐式的类型转换，把它们转换为数值类型再做比较 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:11:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"索引不宜太多，一般5个以内 索引并不是越多越好，虽其提高了查询的效率，但却会降低插入和更新的效率 索引可以理解为一个就是一张表，其可以存储数据，其数据就要占空间 再者，索引表的一个特点，其数据是排序的，那排序要不要花时间呢？肯定要 insert或update时有可能会重建索引，如果数据量巨大，重建将进行记录的重新排序，所以建索引需要慎重考虑，视具体情况来定 一个表的索引数最好不要超过5个，若太多需要考虑一些索引是否有存在的必要 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:13:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"索引不适合建在有大量重复数据的字段上 如性别字段。因为SQL优化器是根据表中数据量来进行查询优化的，如果索引 列有大量重复数据，Mysql查询优化器推算发现不走索引的成本更低，很可能就放弃索引了。 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:15:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"where限定查询的数据 数据中假定就一个男的记录 反例： SELECT id,NAME FROM student WHERE sex=‘男’ 正例： SELECT id,NAME FROM student WHERE id=1 AND sex=‘男’ 理由： 需要什么数据，就去查什么数据，避免返回不必要的数据，节省开销 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:16:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"避免在索引列上使用内置函数 业务需求：查询最近七天内新生儿（用学生表替代下） 给birthday字段创建索引： ALTER TABLE student ADD INDEX idx_birthday (birthday) 当前时间加7天： SELECT NOW() SELECT DATE_ADD(NOW(), INTERVAL 7 DAY) 反例： EXPLAIN SELECT * FROM student WHERE DATE_ADD(birthday,INTERVAL 7 DAY) \u003e=NOW(); 正例： EXPLAIN SELECT * FROM student WHERE birthday \u003e= DATE_ADD(NOW(),INTERVAL 7 DAY); 理由： 使用索引列上内置函数 索引失效： 索引有效： ","date":"2022-01-04","objectID":"/mysql-sqlbest/:18:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"避免在where中对字段进行表达式操作 反例： EXPLAIN SELECT * FROM student WHERE id+1-1=+1 正例： EXPLAIN SELECT * FROM student WHERE id=+1-1+1 EXPLAIN SELECT * FROM student WHERE id=1 理由： SQL解析时，如果字段相关的是表达式就进行全表扫描 字段干净无表达式，索引生效 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:19:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"避免在where子句中使用!=或\u003c\u003e操作符 应尽量避免在where子句中使用!=或\u003c\u003e操作符，否则引擎将放弃使用索引而进行全表扫描。记住实现业务优先，实在没办法，就只能使用，并不是不能使用。如果不能使用，SQL也就无需支持了。 反例： EXPLAIN SELECT * FROM student WHERE salary!=3000 EXPLAIN SELECT * FROM student WHERE salary\u003c\u003e3000 理由： 使用!=和\u003c\u003e很可能会让索引失效 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:20:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"去重distinct过滤字段要少 #索引失效 EXPLAIN SELECT DISTINCT * FROM student #索引生效 EXPLAIN SELECT DISTINCT id,NAME FROM student EXPLAIN SELECT DISTINCT NAME FROM student 理由： 带distinct的语句占用cpu时间高于不带distinct的语句。因为当查询很多字段时，如果使用distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较、过滤的过程会占用系统资源，如cpu时间 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:21:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"where中使用默认值代替null 环境准备： #修改表，增加age字段，类型int，非空，默认值0 ALTER TABLE student ADD age INT NOT NULL DEFAULT 0; #修改表，增加age字段的索引，名称为idx_age ALTER TABLE student ADD INDEX idx_age (age); 反例： EXPLAIN SELECT * FROM student WHERE age IS NOT NULL 正例： EXPLAIN SELECT * FROM student WHERE age\u003e0 理由： 并不是说使用了is null 或者 is not null 就会不走索引了，这个跟mysql版本以及查询成本都有关 如果mysql优化器发现，走索引比不走索引成本还要高，就会放弃索引，这些条件 !=，\u003c\u003e，is null，is not null经常被认为让索引失效，其实是因为一般情况下，查询的成本高，优化器自动放弃索引的 如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思也相对清晰一点 高级SQL优化 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:22:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"批量插入性能提升 大量数据提交，上千，上万，批量性能非常快，mysql独有 多条提交： INSERT INTO student (id,NAME) VALUES(4,‘name1’); INSERT INTO student (id,NAME) VALUES(5,‘name2’); 批量提交： INSERT INTO student (id,NAME) VALUES(4,‘name1’),(5,‘name2’); 理由： 默认新增SQL有事务控制，导致每条都需要事务开启和事务提交；而批量处理是一次事务开启和提交。自然速度飞升 数据量小体现不出来 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:23:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"批量删除优化 避免同时修改或删除过多数据，因为会造成cpu利用率过高，会造成锁表操作，从而影响别人对数据库的访问。 反例： #一次删除10万或者100万+？ delete from student where id \u003c100000; #采用单一循环操作，效率低，时间漫长 for（User user:list）{ delete from student; } 正例： #分批进行删除，如每次500 for(){ delete student where id\u003c500; } delete student where id\u003e=500 and id\u003c1000; 理由： 一次性删除太多数据，可能造成锁表，会有lock wait timeout exceed的错误，所以建议分批操作 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:24:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"伪删除设计 商品状态（state）：1-上架、2-下架、3-删除 理由： 这里的删除只是一个标识，并没有从数据库表中真正删除，可以作为历史记录备查 同时，一个大型系统中，表关系是非常复杂的，如电商系统中，商品作废了，但如果直接删除商品，其它商品详情，物流信息中可能都有其引用。 通过where state=1或者where state=2过滤掉数据，这样伪删除的数据用户就看不到了，从而不影响用户的使用 操作速度快，特别数据量很大情况下 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:25:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"提高group by语句的效率 可以在执行到该语句前，把不需要的记录过滤掉 反例：先分组，再过滤 select job，avg（salary） from employee group by job having job =‘president’ or job = ‘managent’; 正例：先过滤，后分组 select job，avg（salary） from employee where job =‘president’ or job = ‘managent’ group by job; ","date":"2022-01-04","objectID":"/mysql-sqlbest/:27:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"复合索引最左特性 创建复合索引，也就是多个字段 ALTER TABLE student ADD INDEX idx_name_salary (NAME,salary) 满足复合索引的左侧顺序，哪怕只是部分，复合索引生效 EXPLAIN SELECT * FROM student WHERE NAME=‘name1’ 没有出现左边的字段，则不满足最左特性，索引失效 EXPLAIN SELECT * FROM student WHERE salary=3000 复合索引全使用，按左侧顺序出现 name,salary，索引生效 EXPLAIN SELECT * FROM student WHERE NAME=‘陈子枢’ AND salary=3000 虽然违背了最左特性，但MYSQL执行SQL时会进行优化，底层进行颠倒优化 EXPLAIN SELECT * FROM student WHERE salary=3000 AND NAME=‘name1’ 理由： 复合索引也称为联合索引 当我们创建一个联合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则 联合索引不满足最左原则，索引一般会失效，但是这个还跟Mysql优化器有关的 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:28:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"排序字段创建索引 什么样的字段才需要创建索引呢？原则就是where和order by中常出现的字段就创建索引。 #使用*，包含了未索引的字段，导致索引失效 EXPLAIN SELECT * FROM student ORDER BY NAME; EXPLAIN SELECT * FROM student ORDER BY NAME,salary #name字段有索引 EXPLAIN SELECT id,NAME FROM student ORDER BY NAME #name和salary复合索引 EXPLAIN SELECT id,NAME FROM student ORDER BY NAME,salary EXPLAIN SELECT id,NAME FROM student ORDER BY salary,NAME #排序字段未创建索引，性能就慢 EXPLAIN SELECT id,NAME FROM student ORDER BY sex ","date":"2022-01-04","objectID":"/mysql-sqlbest/:30:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"删除冗余和重复的索引 SHOW INDEX FROM student #创建索引index_name ALTER TABLE student ADD INDEX index_name (NAME) #删除student表的index_name索引 DROP INDEX index_name ON student ; #修改表结果，删除student表的index_name索引 ALTER TABLE student DROP INDEX index_name ; #主键会自动创建索引，删除主键索引 ALTER TABLE student DROP PRIMARY KEY ; ","date":"2022-01-04","objectID":"/mysql-sqlbest/:31:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"不要有超过5个以上的表连接 关联的表个数越多，编译的时间和开销也就越大 每次关联内存中都生成一个临时表 应该把连接表拆开成较小的几个执行，可读性更高 如果一定需要连接很多表才能得到数据，那么意味着这是个糟糕的设计了 阿里规范中，建议多表联查三张表以下 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:32:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"inner join 、left join、right join，优先使用inner join 三种连接如果结果相同，优先使用inner join，如果使用left join左边表尽量小 inner join 内连接，只保留两张表中完全匹配的结果集 left join会返回左表所有的行，即使在右表中没有匹配的记录 right join会返回右表所有的行，即使在左表中没有匹配的记录 理由： 如果inner join是等值连接，返回的行数比较少，所以性能相对会好一点 同理，使用了左连接，左边表数据结果尽量小，条件尽量放到左边处理，意味着返回的行数可能比较少。这是mysql优化原则，就是小表驱动大表，小的数据集驱动大的数据集，从而让性能更优 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:33:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"in子查询的优化 日常开发实现业务需求可以有两种方式实现： 一种使用数据库SQL脚本实现 一种使用程序实现 如需求：查询所有部门的所有员工： #in子查询 SELECT * FROM tb_user WHERE dept_id IN (SELECT id FROM tb_dept); #这样写等价于： #先查询部门表 SELECT id FROM tb_dept #再由部门dept_id，查询tb_user的员工 SELECT * FROM tb_user u,tb_dept d WHERE u.dept_id = d.id 假设表A表示某企业的员工表，表B表示部门表，查询所有部门的所有员工，很容易有以下程序实现，可以抽象成这样的一个嵌套循环： List\u003c\u003e resultSet; for(int i=0;i\u003cB.length;i++) { for(int j=0;j\u003cA.length;j++) { if(A[i].id==B[j].id) { resultSet.add(A[i]); break; } } } 上面的需求使用SQL就远不如程序实现，特别当数据量巨大时。 理由： 数据库最费劲的就是程序链接的释放。假设链接了两次，每次做上百万次的数据集查询，查完就结束，这样就只做了两次；相反建立了上百万次链接，申请链接释放反复重复，就会额外花费很多实际，这样系统就受不了了，慢，卡顿 ","date":"2022-01-04","objectID":"/mysql-sqlbest/:35:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["MySQL"],"content":"尽量使用union all替代union 反例： SELECT * FROM student UNION SELECT * FROM student 正例： SELECT * FROM student UNION ALL SELECT * FROM student 理由： union和union all的区别是，union会自动去掉多个结果集合中的重复结果，而union all则将所有的结果全部显示出来，不管是不是重复 union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序 union在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION ","date":"2022-01-04","objectID":"/mysql-sqlbest/:36:0","tags":null,"title":"MySQL优化","uri":"/mysql-sqlbest/"},{"categories":["系统设计"],"content":"幂等设计 ","date":"2021-12-29","objectID":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/:1:0","tags":null,"title":"接口幂等设计","uri":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/"},{"categories":["系统设计"],"content":"一、背景 ","date":"2021-12-29","objectID":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/:1:1","tags":null,"title":"接口幂等设计","uri":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/"},{"categories":["系统设计"],"content":"二、问题 ","date":"2021-12-29","objectID":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/:1:2","tags":null,"title":"接口幂等设计","uri":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/"},{"categories":["系统设计"],"content":"三、思路 ","date":"2021-12-29","objectID":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/:1:3","tags":null,"title":"接口幂等设计","uri":"/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E8%AE%BE%E8%AE%A1/"},{"categories":["Golang"],"content":"一、下载地址 https://golang.google.cn/dl/ ","date":"2021-12-28","objectID":"/goenv/:1:0","tags":null,"title":"Go环境搭建","uri":"/goenv/"},{"categories":["Golang"],"content":"二、环境变量 // 设置环境变量内容 export GOHOME=/Users/qiuyong/Develop/dev_env/goenv export GOROOT=$GOHOME/go export GOPATH=$GOHOME/gopath export PATH=$PATH:$GOROOT/bin:$GOPATH/bin // 生效环境变量 source /home/work/.bash_profile // 检验 go env --json ","date":"2021-12-28","objectID":"/goenv/:2:0","tags":null,"title":"Go环境搭建","uri":"/goenv/"},{"categories":["Golang"],"content":"三、配置环境 go env -w GO111MODULE=\"on\" ## 开启go mod模式 go env -w GONOPROXY=\\*\\*.xxx.com\\*\\* ## 配置GONOPROXY环境变量，所有百度内代码，不走代理 go env -w GONOSUMDB=\\* ## 配置GONOSUMDB，目前有一些代码库还不支持sumdb索引，暂时屏蔽此功能 go env -w GOPROXY=https://goproxy.xxx,direct ## 配置GOPROXY go env -w GOPRIVATE=\\*.xxx.com ","date":"2021-12-28","objectID":"/goenv/:3:0","tags":null,"title":"Go环境搭建","uri":"/goenv/"},{"categories":["系统设计"],"content":"MySQL系统设计 ","date":"2021-12-28","objectID":"/mysql-design/:0:0","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"一、设计要素 ","date":"2021-12-28","objectID":"/mysql-design/:1:0","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"1.1、基础设计 根据业务模式，设计库表结构 根据访问模式，设计索引结构 ","date":"2021-12-28","objectID":"/mysql-design/:1:1","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"1.2、拓展设计 读性能 高可用 数据一致性 垂直拆分 水平拆分 ","date":"2021-12-28","objectID":"/mysql-design/:1:2","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"1.3、设计思考 设计解决什么问题？ 引入什么新的问题？ 如何折衷考虑与解决？ ps：任何技术引入都将引入新问题 ","date":"2021-12-28","objectID":"/mysql-design/:1:3","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"二、读性能提升 ","date":"2021-12-28","objectID":"/mysql-design/:2:0","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"2.1、思考 ","date":"2021-12-28","objectID":"/mysql-design/:2:1","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"2.2、方案 ","date":"2021-12-28","objectID":"/mysql-design/:2:2","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"2.2.1、新增索引 问题 写性能下降：写库表时，同步索引将对性能有所损耗 读性能下降：索引设计不合理，索引占据大量内存，缓存命中率将下降 ","date":"2021-12-28","objectID":"/mysql-design/:2:3","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"2.2.2、主从架构，增加从库 思路一：主从分离，主写从读 问题1：从库太多，导致主从延时增大，不一致问题变大 问题2: 写压力并未降低 思路二：主从分离，从库根据用途决定索引结构 问题：运维成本高，有强状态，导致扩容不方便 ","date":"2021-12-28","objectID":"/mysql-design/:2:4","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"2.2.3、新增缓存，防止雪崩 思路：先读缓存，再读主 问题：从库作用降低 ","date":"2021-12-28","objectID":"/mysql-design/:2:5","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"三、垂直拆分与高可用 ","date":"2021-12-28","objectID":"/mysql-design/:3:0","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"3.1、垂直拆分 垂直拆分方法论：长度较短、访问频率较高、经常一起访问放主表 将库/表进行拆分 拆库：按业务拆库 拆表：大表拆小表 大表会加剧io瓶颈，缓存命中率（数据库页加载-预取）会降低 ","date":"2021-12-28","objectID":"/mysql-design/:3:1","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"3.2、高可用 高可用方法论：冗余和故障转移 问题：数据库有状态，冗余就会引发一致性问题 从库高可用冗余从库 主库高可用冗余主库 ","date":"2021-12-28","objectID":"/mysql-design/:3:2","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"四、数据库一致性 情况一：主从数据冗余，主从数据不一致 方案一：忽略不计 方案二：强制读主 方案三：选择性读主 情况二：主主冗余，主主数据不一致 方案一：ID冲突，不同初始值，相同递增步长 方案二：分布式ID，雪花 方案三 单主服务，影子主不服务 情况三：缓存冗余，数据库与缓存不一致 ","date":"2021-12-28","objectID":"/mysql-design/:4:0","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["系统设计"],"content":"五、水平拆分 场景 场景一：数据结构变更，表结构变化 直接线上改表结构会锁表 场景二：新增从库 场景三：存储介质变化 方案 方案一：停服更新 方案二：online schema change 步骤一：创建新库 步骤二：创建触发器同步数据 步骤三：锁A库，改为readonly 步骤四：B库rename 步骤五：切流量 方案三：追日志 ","date":"2021-12-28","objectID":"/mysql-design/:4:1","tags":null,"title":"MySQL系统设计","uri":"/mysql-design/"},{"categories":["Golang"],"content":"并发编程 ","date":"2021-12-28","objectID":"/concurrent/:1:0","tags":null,"title":"并发编程","uri":"/concurrent/"},{"categories":["Golang"],"content":"一、基本原理 1、程序是怎么跑起来的？ 进程/线程 2、cpu的进化，软件跟着发展？ 速度比较：cpu读写、内存读写、磁盘读写 3、并发编程诞生？ 原子性：线程切换问题，对于cpu来说执行指令也是串行的（count = count + 1） 可见性：多核，核与核之间不可见 有序性：编译器优化，乱序执行导致问题出现。 单例多重检查锁 a. 内存重排 b. CAS -\u003e ABA问题 ","date":"2021-12-28","objectID":"/concurrent/:1:1","tags":null,"title":"并发编程","uri":"/concurrent/"},{"categories":["MySQL"],"content":"一、锁类型 ","date":"2021-12-10","objectID":"/mysql-lock/:1:0","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.1、自增锁 An AUTO-INC lock is a special table-level lock taken by transactions inserting into tables with AUTO_INCREMENT columns. In the simplest case, if one transaction is inserting values into the table, any other transactions must wait to do their own inserts into that table, so that rows inserted by the first transaction receive consecutive primary key values. 自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。 最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。 ","date":"2021-12-10","objectID":"/mysql-lock/:1:1","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.2、共享锁/排他锁 Innodb中实现了标准的行级锁，也就是共享锁/排他锁 2.1、共享锁 目标：事务拿到某一行记录的共享S锁，才能读取这一行，实现读读可并行 语句：select xxx from … share in mode; 2.2、排他锁 目标：事务拿到某一行记录的排他X锁，才可以修改或删除这一行，实现读写/写写互斥 语句：select xxx from … for update ","date":"2021-12-10","objectID":"/mysql-lock/:1:2","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.3、意向锁 InnoDB supports multiple granularity locking which permits coexistence of row-level locks and locks on entire tables. To make locking at multiple granularity levels practical, additional types of locks called intention locks are used. Intention locks are table-level locks in InnoDB that indicate which type of lock (shared or exclusive) a transaction will require later for a row in that table. There are two types of intention locks used in InnoDB (assume that transaction T has requested a lock of the indicated type on table t): Intention shared (IS): Transaction T intends to set S locks on individual rows in table t. Intention exclusive (IX): Transaction T intends to set X locks on those rows. Before a transaction can acquire an S lock on a row in table t, it must first acquire an IS or stronger lock on t. Before a transaction can acquire an X lock on a row, it must first acquire an IX lock on t. The main purpose of IX and IS locks is to show that someone is locking a row, or going to lock a row in the table. 意向锁分为意向共享锁（IS锁）和意向排它锁（IX锁）。根据官方说明，事务请求S锁前先获取IS锁，事务请求X锁前先获取IX锁。 意向锁是指，未来某个时刻，事务可能要加共享/排它锁，先提前声明一个意向。 意向共享锁：它预示，事务有意向想对表中的某些行加共享S锁 意向排它锁：它预示，事务有意向对表中的某些行加排它X锁 意向锁间不互斥，但与S、X锁可能存在互斥关系 S与IS兼容，S与IX互斥、 X与IS互斥、X与IX互斥 ","date":"2021-12-10","objectID":"/mysql-lock/:1:3","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.4、插入意向锁 Insert Intention Lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap. 对已有数据行的修改与删除，必须加强互斥锁X锁，那对于数据的插入，是否还需要加这么强的锁，来实施互斥呢？插入意向锁，孕育而生。 插入意向锁，是间隙锁(Gap Locks)的一种（所以，也是实施在索引上的），它是专门针对insert操作的。它的玩法是多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。 本质上，两个写动作，分别写不同的行，通过插入意向锁试探是否有冲突，若冲突那就gap锁开始作用，若无冲突那就实现插入并发，提升性能。 InnoDB使用共享锁，可以提高读读并发； 为了保证数据强一致，InnoDB使用强互斥锁，保证同一行记录修改与删除的串行性； InnoDB使用插入意向锁，可以提高插入并发； ","date":"2021-12-10","objectID":"/mysql-lock/:1:4","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.5、记录锁（Record Locks） 说明：该论述的前提是，在可重复读隔离下进行事务动作 If the table has no PRIMARY KEY or suitable UNIQUE index, InnoDB internally generates a hidden clustered index on a synthetic column containing row ID values. The rows are ordered by the ID that InnoDB assigns to the rows in such a table. The row ID is a 6-byte field that increases monotonically as new rows are inserted. Thus, the rows ordered by the row ID are physically in insertion order. 针对主键索引在内的唯一索引记录上加锁（若表无任何索引，则会创建一个隐藏主键索引），需注意的是是索引而不是记录，以阻止其他事务插入，更新，删除某一行。 记录锁的执行前提是执行当前读，而不是快照读。其中，间隙锁和临键锁也同理，下面论述也遵循这个原则。 快照读：select … from xxx 当前读：update/delete/select … from xxx for update ","date":"2021-12-10","objectID":"/mysql-lock/:1:5","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.6、间隙锁（Gap Locks） 说明：该论述的前提是，在可重复读隔离下进行事务动作 间隙锁，它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。 存在于非唯一索引中，是Innodb在提交下为了解决幻读问题时引入的锁机制，间隙锁不互斥。 加锁的基本单位是（next-key lock）,他是前开后闭原则 插叙过程中访问的对象会增加锁 索引上的等值查询 给唯一索引加锁的时候，next-key lock升级为行锁 向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁 唯一索引上的范围查询会访问到不满足条件的第一个值为止 ","date":"2021-12-10","objectID":"/mysql-lock/:1:6","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"1.7、临键锁（NextKey Locks） 说明：该论述的前提是，在可重复读隔离下进行事务动作 A next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record. By default, InnoDB operates in REPEATABLE READ transaction isolation level and with the innodb_locks_unsafe_for_binlog system variable disabled. In this case, InnoDB uses next-key locks for searches and index scans, which prevents phantom rows。 临键锁，是记录锁和间隙锁的组合，它的封锁范围，既包括索引记录，又包含索引区间。 默认情况下，innodb使用next-key locks来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。 假设有个数据库表 test(id PK, uname) id(primary key) name (key) value 1 1 1 5 5 5 10 10 10 15 15 15 PK存在以下潜在的临键锁 (-∞, 1] (1, 5] (5, 10] (10, 15] ","date":"2021-12-10","objectID":"/mysql-lock/:1:7","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"二、案例分析 ","date":"2021-12-10","objectID":"/mysql-lock/:2:0","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.1、唯一索引等值查询且有结果 事务A 事务B 事务C SELECT * FROM test WHERE id = 5 FOR UPDATE; SELECT SLEEP(60); 正常 INSERT INTO test VALUES (3, 3, 3); 正常 INSERT INTO test VALUES (8, 8, 8); Commit; 当使用等值查询且存在结果时，只使用记录锁，不产生间隙锁。 ","date":"2021-12-10","objectID":"/mysql-lock/:2:1","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.2、唯一索引等值查询不存在结果 事务A 事务B 事务C /* 开启事务 */ BEGIN; /* 查询并加记录锁 */ SELECT * FROM test WHERE id = 7 FOR UPDATE; SELECT SLEEP(60); 阻塞 INSERT INTO test VALUES (8, 8, 8); 正常 INSERT INTO test VALUES (10, ‘wangle’, 10); commit; 当使用等值查询且不存在结果时，使用临键锁。 id=7不存在记录，即加临键锁 (5, 10] 由于数据是等值查询，并且范围的最后数据id=10不满足要求，退化为间隙锁(5,10) id = 8 写入失败，写id=10 成功 ","date":"2021-12-10","objectID":"/mysql-lock/:2:2","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.3、唯一索引范围查询 2.3.1、范围开区间 事务A 事务B 事务C BEGIN; SELECT * FROM test WHERE id \u003c 13 for update; SELECT SLEEP(60); #阻塞 insert into test values(14,14,14); #阻塞 update test set value = value +1 where id = 15; commit; 命中区间为(-∞, 13)，13命中的临键锁区间为(10, 15]，因为不是等值查询，所以不会降级为间隙锁(10, 15)，综合看锁止的区间为(-∞, 15]； 事务A 事务B 事务C BEGIN; SELECT * FROM test WHERE id \u003e 13 for update; SELECT SLEEP(60); #阻塞 insert into test values(11,11,11); #正常 update test set value = value +1 where id = 10; commit; 命中的区间为(13, +∞)，13命中的临键锁区间为(10, 15]，所以综合看锁止的区间为(10, +∞)； 2.3.2、范围闭区间 事务A 事务B 事务C BEGIN; SELECT * FROM test WHERE id \u003e= 10 for update; SELECT SLEEP(60); #正常 insert into test values(9,9,9); #阻塞 update test set value = value +1 where id = 10; commit; 命中的区间为(10, +∞)，因为条件包含等于，所以左区间升级为闭区间，[10, +∞)。 事务A 事务B 事务C 事务D BEGIN; SELECT * FROM test WHERE id \u003c= 10 for update; SELECT SLEEP(60); #阻塞 insert into test values(3,3,3); #阻塞 insert into test values(14,14,14); #阻塞update test set value = value +1 where id = 15; commit; id \u003c= 10表示的范围为(-∞, 10]，因为是范围查询，所以会遍历下一个区间(10,15]，因为是范围查询，即使15未命中也不会退化为开区间。综合看锁定的范围为(-∞, 15] ","date":"2021-12-10","objectID":"/mysql-lock/:2:3","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.4、普通索引等值查询存在结果 事务A 事务B 事务C 事务D BEGIN; SELECT * FROM test WHERE name = 5 for update; SELECT SLEEP(60); #阻塞 insert into test values(3,3,3); #阻塞 insert into test values(9,9,9); #正常 update test set value = value +1 where name = 10; commit; 普通索引等值查询会直接使用间隙锁，并且会向右遍历一个区间。 name = 5 命中(1, 5]，向右遍一个区间为(5,10]，因为是等值查询且10不满足条件，所以降级为(5,10)，综合来看锁止的空间为(1,10)，所以事务B和C会被阻塞，事务D正常。 ","date":"2021-12-10","objectID":"/mysql-lock/:2:4","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.5、普通索引等值查询不存在结果 事务A 事务B 事务C 事务D BEGIN; SELECT * FROM test WHERE name = 6 for update; SELECT SLEEP(60); #正常 insert into test values(3,3,3); #阻塞 insert into test values(9,9,9); #正常 update test set value = value +1 where name = 10; commit; name = 6 不存在记录，所以命中的区间为(5,10]，因为10 不满足条件，所以降级为(5,10)。事务B和D正常，事务C被阻塞。 ","date":"2021-12-10","objectID":"/mysql-lock/:2:5","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"2.6、普通索引范围查询 事务A 事务B 事务C 事务D BEGIN; SELECT * FROM test WHERE name \u003c 13 for update; SELECT SLEEP(60); #阻塞 insert into test values(3,3,3); #阻塞insert into test values(14,14,14); #阻塞update test set value = value +1 where name = 15; commit; name \u003c 13 表示的范围为 (-∞, 13)，因为13 位于(10,15]区间，并且非等值查询，即使15未命中也不会降级为开区间，综合看锁止的范围为(-∞, 15]。 事务A 事务B 事务C 事务D BEGIN; SELECT * FROM test WHERE name \u003c= 10 for update;SELECT SLEEP(60); 阻塞insert into test values(3,3,3); #阻塞 insert into test values(14,14,14); #阻塞update test set value = value +1 where name = 15; commit; name \u003c=10 表示的范围为(-∞, 10]，10命中的区间为(5,10]；因为是范围查询，所以会向右遍历一个区间(10,15]，并且即使15未命中也不会退化为(10,15)；综合来看，命中的区间为(-∞, 15]。所以事务B、C、D都会被阻塞。 事务A 事务B 事务C BEGIN; SELECT * FROM test WHERE name \u003e 13 for update; SELECT SLEEP(60); #阻塞 insert into test values(11,11,11); #正常 update test set value = value +1 where name = 10; commit; name \u003e 13 表示的范围为(13, +∞)，13命中的间隙范围为(10,15]，所以综合看，锁定的范围为(10, +∞)，事务B阻塞，事务C正常。 【分析总结】 唯一索引 普通索引 等值查询有结果 记录锁 间隙锁，取值的前后相邻两个区间 等值查询无结果 临键锁，取值所在的区间 临键锁，取值所在的区间 \u003c x || \u003c=x (-∞, y] x在表中存在时，y为x所在区间向右一个区间的上界 x在表中不存在时，y为x所在区间的上界 (-∞, y] x在表中存在时，y为x所在区间向右一个区间的上界 x在表中不存在时，y为x所在区间的上界 \u003ex (y, +∞) x在表中存在时，y=x x在表中不存在时，y为x所在区间的下界 (y, +∞) x在表中存在时，y=x x在表中不存在时，y为x所在区间的下界 \u003e=x [y, +∞) x在表中存在时，y=x x在表中不存在时，y为x所在区间的下界 [y, +∞) x在表中存在时，y=x x在表中不存在时，y为x所在区间的下界 ","date":"2021-12-10","objectID":"/mysql-lock/:2:6","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"三、死锁分析 INSERT sets an exclusive lock on the inserted row. This lock is an index-record lock, not a next-key lock (that is, there is no gap lock) and does not prevent other sessions from inserting into the gap before the inserted row. Prior to inserting the row, a type of gap lock called an insert intention gap lock is set. This lock signals the intent to insert in such a way that multiple transactions inserting into the same index gap need not wait for each other if they are not inserting at the same position within the gap. Suppose that there are index records with values of 4 and 7. Separate transactions that attempt to insert values of 5 and 6 each lock the gap between 4 and 7 with insert intention locks prior to obtaining the exclusive lock on the inserted row, but do not block each other because the rows are nonconflicting. If a duplicate-key error occurs, a shared lock on the duplicate index record is set. This use of a shared lock can result in deadlock should there be multiple sessions trying to insert the same row if another session already has an exclusive lock. 简单说就是insert执行时会给目标行加排他锁，是记录锁；不过在insert执行前，会先加insertion intention gap lock，意向插入锁，是间隙锁。 如果发生了唯一键冲突错误，那么将会在重复的索引记录上加读锁。当有多个session同时插入相同的行记录时，如果另外一个session已经获得该行的排它锁，那么将会导致死锁。 insert into xxx values(…) on duplicate key update ….. 产生死锁的原因分析 事务A 事务B acquire X lock;duplicate;release X lock;acquire S lock; acquire X lock; duplicate;release X lock;acquire S lock; prepare update;try acqure X lock; prepare update;try acqure X lock; waiting S lock from B waiting S lock from A ","date":"2021-12-10","objectID":"/mysql-lock/:3:0","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"参考资料 MySQL锁类型@架构师之路 ","date":"2021-12-10","objectID":"/mysql-lock/:4:0","tags":null,"title":"MySQL锁的实现原理","uri":"/mysql-lock/"},{"categories":["MySQL"],"content":"MySQL事务原理 ","date":"2021-12-09","objectID":"/mysql-transaction/:0:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"1、事务是什么？ 事务通常指的是逻辑上的一组操作，要么全部执行成功，要么全部执行失败。总体来说，他们具备ACID四大特性，分别是原子性（Atomioc）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。其中，事务的隔离型由锁和MVCC机制实现啊，原子性和持久性由RedoLog实现，一致性由UndoLog实现的。 原子性：事务的所有操作要么全部成功，要么全部失败。 一致性：事务执行之前和执行之后，数据始终处于一致的状态。 隔离型：并行执行的两个事务互相不受干扰。 持久性：事务提交之后，此事务对数据的更改操作被持久化到数据库中，并且不会被回滚。 ","date":"2021-12-09","objectID":"/mysql-transaction/:1:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"2、事务并发会产生什么问题？ 并发问题是程序无法避免的问题，核心是并发事务对同一临界资源进行操作，不进行管控就会产生不一致。 举个例子：假设有一张数据表，user(uid, account)，实际数据为user（123, 100） A、问题1：脏读 1. 事务A：insert into user value(456, 200); 未提交 2. 事务B：select account from user where uid = 456; 读到account的值为200 事务B中读到了事务A未提交数据，说明是脏读。 B、问题2: 不可重复读 1. 事务A：update account = account + 100 where uid = 123 2. 事务B：select account from user where uid = 123，该处读到的acount = 100（A未提交） 3. 事务A：commit 4. 事务B：select account from user where uid = 123，该处读到的acount = 200（A已提交） 事务B两次读同一数据，读到前后结果分别是100、200，说明是不可重复读。 C、问题3: 幻读 1. 事务A：select * from user; // 查询结果: user(123, 100) 2. 事务B：insert into user value(456, 200); commit; 3. 事务A: select * from user; // 查询结果：user(123, 100) 4. 事务A：update user set account = 300 where uid = 456; commit; // 刚刚查询结果还不存在uid=456，更新居然成功了！ 5. 事务A: select * from user; // 查询结果：user(123, 100)、user(456, 300) 从例子看，都是已提交的事务A对事务B造成了影响。不可重复读和幻读的区别是什么呢？ 不可重复读：主要是针对修改和删除动作，两次读的结果是不一样的，被称为不可重读（变化）。 幻读：主要是针对插入动作，第一次读不存在，第二次读存在，被称为幻读（有无）。 ","date":"2021-12-09","objectID":"/mysql-transaction/:2:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"3、如何解决并发事务产生的问题？ 并发问题在程序中通常控制手段有两种：悲观锁（互斥锁、读写锁）、乐观锁（CAS + 数据多版本）。 ","date":"2021-12-09","objectID":"/mysql-transaction/:3:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"3.1、在并发控制中，锁机制是如何演进的？ 我们知道，并发问题的核心是数据竞争，解决办法是临界资源管控(锁)。然而，锁机制演进的过程在本质上是性能和安全的折中。我们在应用程序中，解决并发问题通常手段有如下几种。 互斥锁：最简单粗暴的办法是互斥锁，读写全部都串行化。它的优点是安全，缺点是性能差。 读写锁：按理说读读是对数据一致性不会产生影响，于是读写锁产生实现读读并行，读写、写写串行，提升性能。 CAS+数据多版本：CAS是自旋锁摆脱锁机制，但是CAS会存在ABA问题，于是通过数据多版本来解决ABC问题保障安全。同时，实现读写并行，进一步提升性能。 名次解释：CAS（Compare And Swap）、ABA问题（百度一下） 总体思路，简单总结一下。 互斥锁：无论读还是写全部串行执行。 读写锁：读读并行执行，读写、写写串行执行。 数据多版本：读写并行执行。 ","date":"2021-12-09","objectID":"/mysql-transaction/:3:1","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"3.2、MySQL中是如何解决并发问题的？ MySQL中是通过隔离性来保证，隔离性的底层实现是通过锁和MVCC（数据多版本）保证。从总体思路说，它的解决办法思路跟通常手段是一致的。谈到隔离性就不得不谈到隔离级别，事务中存在四种隔离级别分别是读提交、读已提交、可重复读、串行化。 3.2.1、这几种隔离级别是什么含义呢？ 举个例子：假设有一张数据表，user(uid, account)，实际数据为user（123, 100） A、读未提交 事务A：update account = account + 100 where uid = 123 事务B：select account from user where uid = 123，该处读到的account = 200（A未提交） 点评：事务A修改数据且提交，事务B马上可见，存在脏读。 B、读提交 事务A：update account = account + 100 where uid = 123 事务B：select account from user where uid = 123，该处读到的acount = 100（A未提交） 事务A：commit 事务B：select account from user where uid = 123，该处读到的acount = 200（A已提交） 点评：事务A修改数据且提交，事务B马上可见，存在不可重复读。 C、可重复读 简单说，事务在未提交前查询的同一条数据，无论读多少遍都不会改变。 事务B：select account from user where uid = 123，该处读到的acount = 100 事务A：update account = account + 100 where uid = 123；commit； （更新且提交） 事务B：select account from user where uid = 123，该处读到的acount = 100（A提交不影响B） 点评：事务A修改数据无论是否提交，事务B都不可见。 D、串行化 简单说，前一个事务没有提交事务前，下一个事务不允许进行数据操作，不过多赘述。 3.2.2、不同隔离级别分别能解决那些事务并发问题（脏读、不可重复读、幻读）？ 事务隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 串行化 不可能 不可能 不可能 读未提交：普通select不加锁 串行化：普通select隐式加锁，普通select全部转换成加锁select（select … in share mode） 可重复读（RR）：普通select为快照读，update/delete/加锁select（select … in share mode / for update）为当前读（行锁），存在幻读问题 唯一索引查询条件（记录锁）、范围查询（gap lock 和 nextkey lock） 读已提交（RC）：普通select为快照读，update/delete/加锁select（select … in share mode / for update）为当前读（行锁） 唯一索引查询条件（记录锁） 3.2.3、Mysql是如何在可重复读隔离级别解决幻读问题的？ 众所周知，数据多版本只能解决可重复读问题（行记录多版本），并不能控制记录新增产生的幻读问题。MySQL中解决幻读问题，主要是通过记录锁、间隙锁和nextkey锁。 间隙锁：本质上是事务未结束前，不允许其他记录新增记录。其中，间隙锁住要作用于范围查询。 假设有个数据库表,user(id, uid, account)，存在如下记录 user(1, 111, 100) user(2, 222, 200) user(20, 333, 300) user(24, 444, 400) 该数据表存在间系：[3,20)、[20,24),[25,+∞) 事务：select * from user id \u003e 20 for update; // 这时候间隙[21,24)、[25, +∞]都会被间隙锁锁住，24会被记录锁锁住 3.2.4、MVCC（Multi Version Concurrent Control）是如何实现的？ 3.2.4.1、MVVC被称为多版本并发控制，什么是数据多版本？ 例3.2-1：假设有张数据表，数据表为user(uid, account)，初始化数据为user(123, 100) 执行SQL语句: start; update user set account = 200 where uid = 123; update user set account = 300 where uid = 123; update user set account = 400 where uid = 123; commit; 按照正常思想，执行完SQL的数据存储结构 user(123, 400) 按照数据多版本思想，执行玩SQL的数据存储结构 user(123, 100, V1) user(123, 200, V2) user(123, 300, V3) user(123, 400, V4) 注意：这里的快照是基于每一行的行数据变更快照。 据上总结，数据多版本就是将数据做冗余，存储每一个时刻行记录变更的镜像。那么，事务之间的数据镜像无依赖且能找到历史数据版本，从而实现数据读写并发、事务回滚。 3.2.4.2、MySQL的MVCC机制底层是如何实现的？ 行记录的隐藏列 假设我们来设计数据多版本，按照最简单思路（例3.2-1），不考虑资源限制条件下直接在磁盘存多份数据就能实现这种效果，但显然存在存储资源问题，故不会被采用。 那在Innodb存储引擎中如何实现做的呢？首先，在数据库中有个概念叫做隐藏列，也就是每一行数据都有隐藏列数据，它们分别是TRX_ID、ROW_ID、ROLLBACK_POINTER TRX_ID：更新该行数据的事务ID ROW_ID：该行的唯一标识ID（当无主键时存在） ROLLBACK_POINTER：回滚指针，它指向上一个版本，我们把指向的地址回滚段中undolog的指针 **undolog** **上面提到的undolog，什么意思？**undolog是食事务未提时，会将事务旧版本的数据存放于undolog日志里，当事务回滚或数据崩溃时，可以利用undo日志，撤销未提交事务对数据的影响。 undolog存什么？ insert：undolog日志存储新数据的ROW_ID(PK)，回滚时删除即可 delete/update：undolog存储旧版本数据的行记录，回滚时直接恢复即可 回滚段 回滚段是存储undolog的地方，一个回滚段对应一次事务执行的undolog集合（事务与回滚段的映射关系存在，便于快速查找到事务的历史数据版本快速回滚）。 快照（ReadView） 快照是什么？快照就是基于整库的某个时刻的镜像。在不同隔离级别下快照（READVIEW）产生时机不同，可重复读隔离级别是事务启动时产生快照，读已提交隔离级别是执行更新动作时产生快照。 首先，基于整库镜像，当然不是物理存储，假设整库100G，每个镜像100G，那数据库得崩溃。于是，就有了ReadView的数据结构来定义。 m_ids：当前系统中存活的事务id的列表 min_trx_id：当前系统中存活事务的最小事务id，即m_ids的最小值 max_trx_id：系统下一个即将分配的事务id，**即m_ids的最大值 + 1，**并不是m_ids的最大值 creator_trx_id：当前事务ID 其中，(-∞，min_trx_id)为已提交事务，[min_trx_id,max_trx_id)为未提交事务, [max_trx_id, +∞]为未开始事务。通过这个规则来定义进行快照读的时候，确认行记录是否可读。 如果落在已提交事务区间，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在未提交事务区间，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在未开始事务区间，那就包括两种情况 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 总之，根据数据行中ROLLBAKCK_PTR能找到所有的回滚日志（历史版本数据），通过快照中事务活跃关系和数据行中TRX_ID来比对确定是否可读来执行快照读，最终实现了MVCC中数据多版本并发读写效果。 ","date":"2021-12-09","objectID":"/mysql-transaction/:3:2","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"4、事务的执行流程 ","date":"2021-12-09","objectID":"/mysql-transaction/:4:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"4.1、事务是如何执行的？ ","date":"2021-12-09","objectID":"/mysql-transaction/:4:1","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"4.2、事务是如何回滚的？ 根据事务ID找到对应的回滚段中的undolog，将回滚段里的日志进行清空即可。 ","date":"2021-12-09","objectID":"/mysql-transaction/:4:2","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"5、数据库事务是怎么实现的？ 参考：https://draveness.me/mysql-transaction/ 原子性和持久性由RedoLog实现，一致性由UndoLog实现，隔离性由MVCC和锁实现。 ","date":"2021-12-09","objectID":"/mysql-transaction/:5:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"5.1、原子性\u0026持久性 严格说，原子性和持久性由RedoLog和UndoLog保证。当然，说RedoLog也是可接受的，因为UndoLog也会产生RedoLog。UndoLog的完整性和可靠性需要RedoLog保证，因此数据库崩溃时需要先做RedoLog恢复，然后再做UndoLog回滚。 总之，RedoLog的持久化保证了数据持久化到磁盘，又影响到UndoLog的可靠和完整，最终实现原子性和持久性。UndoLog用于对事务的影响进行撤销，RedoLog在错误处理时，对已提交的事务进行重做。 发生错误或需要回滚的事务能够成功回滚（原子性）； 在事务提交后，数据没得急写磁盘就宕机时，在下次重新启动后能够恢复数据（持久性）； ","date":"2021-12-09","objectID":"/mysql-transaction/:5:1","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"5.3、一致性 原子性\u0026持久性\u0026原子性都保证了，一致性就保证了。 不一致的时机：unlog、redolog、磁盘都可能出现不一致 A时机：写了redolog，写磁盘失败 redolog：数据页记录与磁盘页比较，通过回放实现磁盘和redolog的一致 B时机：事务已提交，redolog写失败 undolog/binlog：数据进行比较实现一致 ","date":"2021-12-09","objectID":"/mysql-transaction/:5:2","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"5.4、隔离性 MVCC和锁 ","date":"2021-12-09","objectID":"/mysql-transaction/:5:3","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"参考 MySQL技术内幕InnoDB存储引擎 深入理解分布式事务 https://draveness.me/mysql-transaction/ InnoDB-事务原理@www.corgiboy.com InnoDB并发如此高，原因竟然在这？@架构师之路 MySQL-InnoDB究竟如何巧妙实现，4种事务的隔离级别@架构师之路 https://www.cnblogs.com/rjzheng/p/10841031.html ","date":"2021-12-09","objectID":"/mysql-transaction/:6:0","tags":null,"title":"MySQL事务实现原理","uri":"/mysql-transaction/"},{"categories":["MySQL"],"content":"1、数据库与缓存不一致问题 ","date":"2021-12-09","objectID":"/mysql-problem/:1:0","tags":null,"title":"MySQL实践难题","uri":"/mysql-problem/"},{"categories":["MySQL"],"content":"1.1、问题产生 为什么用缓存？ 提升读性能：db受限于磁盘限制，缓存基于内存，磁盘与内存的读性能想差甚远 会产生什么问题？ 数据不一致：数据冗余意味着不一致 ","date":"2021-12-09","objectID":"/mysql-problem/:1:1","tags":null,"title":"MySQL实践难题","uri":"/mysql-problem/"},{"categories":["MySQL"],"content":"1.2、解决办法 要点：并发（时序）、异常情况 指标：缓存利用率、并发安全、一致性 1.2.1、MySQL单机版 最佳实践：先更新数据库，再删除缓存 方案一：更新数据库、更新缓存 思路 先更新数据库，再更新缓存 先更新数据库，再更新缓存 问题 异常问题：第一步更新成功，第一步更新失败，必将导致不一致。 并发问题：并发必将有时序问题。 例子 A线程更新数据库（X=1），B线程更新数据库（X=2） B线程更新缓存（X=2），A线程更新缓存（X=1） 结果：X的值，数据库=2，缓存=1，不一致持续时长取决于缓存过期时间 结论：该方案原则上不推荐使用，主要是时序问题无法保证 方案二：更新数据库、删除缓存 思路 先删除缓存，再更新数据库 先更新数据库，再删除缓存 问题 异常问题：跟第一种方案同理无法避免，异常必将导致不一致 并发问题 先删除缓存，再更新数据库 例子 1、线程A要更新X=2（原值X=1） 2、线程A先删除缓存 3、线程B读取缓存，发现不存在，从数据库读取旧值（X=1） 4、线程A将新值写入数据库（X=2） 5、线程B将旧值写入缓存（X=1） 结果：X的值，数据库=2，缓存=1 分析：读写请求并发，A、B线程交替读写，出现概率还是可能的。 先更新数据库，再删除缓存 例子 1、缓存中 X 不存在（数据库 X = 1） 2、线程 A 读取数据库，得到旧值（X = 1） 3、线程 B 更新数据库（X = 2) 4、线程 B 删除缓存 5、线程 A 将旧值写入缓存（X = 1） 结果：X的值，数据库=2，缓存=1 分析：出现时机且满足以下三个条件，现实中出现概率较少，存在理论上的可能 线程A读请求时，缓存已失效 读写请求并发 步骤2中读时长 \u003e 「步骤3+步骤4」中的「更新+删除」动作总时长概率较低 结论：「先更新数据库，再删除缓存」从分析结果来看能绝大概率解决并发问题，是该命中的最佳实践。 根据「先更新数据库，再删除缓存」仅解决并发问题，如何解决异常问题？ 思路一：一致性要求不高，容忍短暂不一致，等待缓存到过期时间，不处理 思路二：删缓存动作失败，尝试充实重试 同步重试：仅在网络抖动丢包的情况 异步重试：写MQ异步读取消费，MQ需保证可靠性直到消费成功 思路三：监听MySQL的binlog，思路就跟主从原理类似，实现缓存同步。 市场上现有工具可参考阿里的canal，「数据库+缓存」、「数据库 + es索引」 1.2.2、MySQL主从 + 读写分离 问题：MySQL主从 + 读写分离架构中，读请求存在延迟导致不一致？ 线程 A 更新主库 X = 2（原值 X = 1） 线程 A 删除缓存 线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1） 从库「同步」完成（主从库 X = 2） 线程 B 将「旧值」写入缓存（X = 1） 结果： X 的值在缓存中是 1（旧值），在主从库中是 2（新值），也发生不一致。 分析：在有大事务或资源抢占明显时，主从延时的概率还是存在的，故发生的概率还是会存在 思路：根据经验，预估主从延时时间，将缓存再次删除 方案一：更新数据库，删除缓存，休眠等待延时时间，再次删除缓存 方案二（推荐）：更新数据库，将删动作写入延时队列（延时时间根据经验1-5s），定期消费消息执行删除动作 方案三：选择性读主，更新数据库时，记录「库 + 表 + pk」作为键记录到缓存中，读db时根据该键决定是否读主 总结：最佳实践选择「先更新数据库，再删除缓存」的方案实现数据库与缓存一致，根据业务一致性要求和MySQL主从+读写分离架构考虑是否要使用延迟删除方案。 实践：写多读少场景保db高可用，读多写少做缓存高可用 + 容灾缓存。 其他：很多时候，缓存也存在主从架构，甚至还有跨机房延迟等情况，实际从理论上提出完美方案就非常复杂了。最佳办法还是保证每一个子系统子服务保证一致，写的代码保障高质量避免极端情况出现，故才能达到全局最优的方案。 ","date":"2021-12-09","objectID":"/mysql-problem/:1:2","tags":null,"title":"MySQL实践难题","uri":"/mysql-problem/"},{"categories":["MySQL"],"content":"2、数据库与ES同步问题 问题起源：在用户产品研发中，经常会碰到很多复杂多样的查询，如标签、分类、人群等，而实际的元数据却存在于关系型数据库MySQL，关系型数据库对于复杂查询很难支持，同时它也不适合承担太多索引的职责。于是，引入ES充当索引角色，也就是形成复杂标签与原数据ID成映射关系。 读请求：查询es索引，找到索引与元数据ID，通过元数据ID查MySQL具体数据，最终返回 写请求 方式一（同步写）：写MySQL、写ES索引，存在写失败问题，扩展性也不好 方式二（异步写） 来源一：监听MySQL的binlog，将binlog写入MQ，解析binlog将数据同步到ES 来源二：业务制定日志规范，打印用户日志，采集用户日志，流式计算日志，将日志导入ES ","date":"2021-12-09","objectID":"/mysql-problem/:2:0","tags":null,"title":"MySQL实践难题","uri":"/mysql-problem/"},{"categories":["MySQL"],"content":"参考资料 数据库与缓存一致性问题@水滴与银弹 ","date":"2021-12-09","objectID":"/mysql-problem/:3:0","tags":null,"title":"MySQL实践难题","uri":"/mysql-problem/"},{"categories":["效率工具"],"content":"图床 网址：https://www.jsdelivr.com/?docs=gh 示例：https://cdn.jsdelivr.net/gh/piqiu96/aqiucdn/imgs/wxicon2.jpg ","date":"2021-12-05","objectID":"/write_tool/:1:0","tags":["写作"],"title":"写作工具","uri":"/write_tool/"},{"categories":["效率工具"],"content":"公众号排版 https://www.mdnice.com/ http://md.aclickall.com/ http://blog.didispace.com/tools/online-markdown/ ","date":"2021-12-05","objectID":"/write_tool/:2:0","tags":["写作"],"title":"写作工具","uri":"/write_tool/"},{"categories":["效率工具"],"content":"代码排版 https://carbon.now.sh/ ","date":"2021-12-05","objectID":"/write_tool/:3:0","tags":["写作"],"title":"写作工具","uri":"/write_tool/"},{"categories":["阅读书单"],"content":"Golang 《Go 学习笔记（第 4 版）》 《Go 学习笔记（第 6 版下卷）》 《Go 源码剖析》 《Go 程序设计语言》 《Go 语言实战》 ","date":"2021-10-14","objectID":"/booklist/:1:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Python 《Python Cookbook（第 3 版）》 《Python 源码剖析》 ","date":"2021-10-14","objectID":"/booklist/:1:1","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Computer system 《深入理解计算机系统》 《现代操作系统（第 4 版）》 《编码：隐匿在计算机软硬件背后的语言》 《计算机程序的构造和解释（第 2 版）》 《计算的本质：深入剖析程序和计算机》 ","date":"2021-10-14","objectID":"/booklist/:2:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Linux / Unix 《UNIX 编程艺术》 《UNIX 环境高级编程（第三版）》 《UNIX 网络编程卷 1：套接字 API》 《UNIX 网络编程卷 2：进程间通信》 《UNIX 操作系统设计》 《Linux 内核设计与实现（第三版）》 《深入 Linux 内核架构》 《深入理解 linux 内核（第三版）》 《跟我一起写 makefile》 ","date":"2021-10-14","objectID":"/booklist/:3:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Clean code 《代码整洁之道》 《代码大全》 《编写可读代码的艺术》 《修改代码的艺术》 《重构：改善既有代码的设计》 《程序设计方法》 《程序设计实践》 《领域驱动设计：软件核心复杂性应对之道》 ","date":"2021-10-14","objectID":"/booklist/:4:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Design pattern 《Head First 设计模式》 《设计模式：可复用面向对象软件的基础》 《设计模式之禅》 ","date":"2021-10-14","objectID":"/booklist/:5:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Algorithms 《算法心得：高效算法的奥秘（第 2 版）》 《数据结构与算法分析：C 语言描述（第 2 版）》 《数据结构与算法分析：Java 描述》 《编程珠玑（第 2 版）》 《编程之美：微软技术面试心得》 《剑指 offer 名企面试官精讲典型编程题》 ","date":"2021-10-14","objectID":"/booklist/:6:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"System 《高性能网站建设指南》 《大型网站技术架构：核心原理与案例分析》 《企业应用架构模式》 《企业集成模式：设计、构建及部署消息传递解决方案》 ","date":"2021-10-14","objectID":"/booklist/:7:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Git 《Pro Git 中文版》 《GitHub 入门与实践》 ","date":"2021-10-14","objectID":"/booklist/:8:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"MySQL 《高性能 MySQL（第 3 版）》 《MySQL 性能调优与架构设计》 《MySQL 技术内幕：InnoDB 存储引擎》 《MySQL 必知必会》 ","date":"2021-10-14","objectID":"/booklist/:9:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Redis 《Redis 入门指南（第 2 版）》 《Redis 实战》 《Redis 设计与实现》 《Redis 开发与运维》 ","date":"2021-10-14","objectID":"/booklist/:10:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":["阅读书单"],"content":"Others 《如何阅读一本书》 《七周七语言：理解多种编程范型》 《程序员修炼之道：从小工到专家》 《程序员的职业素养》 《程序员的自我修养：链接、装载与库》 《高效程序员的 45 个习惯》 ","date":"2021-10-14","objectID":"/booklist/:11:0","tags":null,"title":"经典技术书单","uri":"/booklist/"},{"categories":null,"content":"一、概念 ","date":"2020-12-04","objectID":"/git%E5%AE%9E%E6%88%98/:1:0","tags":null,"title":"Git速查","uri":"/git%E5%AE%9E%E6%88%98/"},{"categories":null,"content":"1.1. Git是什么？ GIT是分布式版本控制系统，简单分解就是：分布式 + 版本控制 + 系统，核心要素就是版本控制。 问题：怎么理解版本控制，想想我们生活工作中的场景？ 1、假设没有版本控制系统，你上线代码会做什么事情？（假设你不做，出现问题你怎么办？） 备份原文件，重命名 niubi.php.20200520 复制修改后文件移动到制定项目路径 2、当我们还是单机mysql数据库，对稳定要求不高，只需具备快速切换能力即可，这种场景你会怎么做？ 方案一：对数据库做版本控制，定时dump数据库文件，数据库文件名（XX.sql.时间时刻） 方案二：做数据库主从，主库挂掉，脚本快速切换到从库 3、当你写毕业论文的时候，写了N年的论文丢了你怕不怕，为了防止这操作你常见的操作是什么？ 老师想看论文，阿邱同学提交论文，命名：阿邱同学毕业论文_V1 老师想看论文，阿邱同学提交论文，命名：阿邱同学毕业论文_V2 …… 老师想看论文，阿邱同学提交论文，命名：阿邱同学毕业论文_V死不改版 本质上，版本控制本质上就是把每次文件（数据）集合打个标记（版本），让自己快速跳转到目标版本。最终，实现代码可以随意切换到随意版本的代码，当出现问题能快速切换到稳定版本。 ","date":"2020-12-04","objectID":"/git%E5%AE%9E%E6%88%98/:1:1","tags":null,"title":"Git速查","uri":"/git%E5%AE%9E%E6%88%98/"},{"categories":null,"content":"1.2 为什么要用Git？ 不管人类还是软件，都会遇到类似的问题，版本控制系统诞生无非是苦秦久矣罢了。还有细心思考下，不光是代码，凡是需要存储的内容（文件、数据库）都需要版本控制，不然任何一环故障都会影响系统。 其实，在Git出现前就出现很多版本控制系统，主流思想无非就是增量或全量，Git采用的全量快照的方式，把修改的文件集合打个版本。 增量：每次记录变化的内容，恢复的时候依据 基准版本 + 增量版本回滚。 全量：每次记录本次变更的所有文件放入缓存区，恢复的时候直接缓存区找到全量版本回滚。 于是，GIt有几个核心流程和核心概念。 核心概念：文件流转状态（已提交、已修改、已暂存），为了可通过文件状态跟踪出文件内容，于是git项目有三个阶段：工作区、暂存区以及 Git 目录。 核心流程： 在工作区中修改文件。 将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。 提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。 ","date":"2020-12-04","objectID":"/git%E5%AE%9E%E6%88%98/:1:2","tags":null,"title":"Git速查","uri":"/git%E5%AE%9E%E6%88%98/"},{"categories":null,"content":"二、实战 场景一：添加如何代码，提cr git pull git add \u003cfile\u003e git commit -m \"commit message\" 场景二：回滚commit 说明 提交非预期代码，需要回滚重新提交 git log git reset --soft '版本号' git reset --soft HEAD^ 回滚到上次提交 场景三: 切换分支且拉取代码 说明 主要用于项目初始化，切换分支且拉取代码 git branch -a git checkout -b \u003cbranch_local\u003e orign/\u003cbranch_remote\u003e baranch_local: 本地分支名，可自定义随意 branch_remote：远程分支名，必须是仓库内名 场景四：多个commit合并 说明 通常情况，我们设置一次CR只允许一次commit，如何把多次commit合并到同一commit？ git reset --soft HEAD^ git commit --amend git push origin \u003cremote\u003e 场景五：代码冲突 说明 代码冲突是最常见的问题，也是很头大的问题 方法一：保留服务器改动，仅合入远程仓库新增配置项，标记出冲突代码！ git stash git pull git stash pop 方法二：用远程仓库代码库文件完全覆盖本地文件，强制回滚！（慎用） git reset --hard git pull ","date":"2020-12-04","objectID":"/git%E5%AE%9E%E6%88%98/:2:0","tags":null,"title":"Git速查","uri":"/git%E5%AE%9E%E6%88%98/"},{"categories":null,"content":"参考资料 https://www.liaoxuefeng.com/wiki/896043488029600 https://git-scm.com/book/zh/v2 ","date":"2020-12-04","objectID":"/git%E5%AE%9E%E6%88%98/:3:0","tags":null,"title":"Git速查","uri":"/git%E5%AE%9E%E6%88%98/"},{"categories":["成长日记"],"content":"01、问题 2019年马上就要向我们挥手告别，你是否还记得年初你对自己许下了什么心愿吗？ 呃，记得… 那你今年的目标或愿望完成了吗？不管如何，请务必做好总结和反思。因为你2020的目标即将发射，是会永久的定格在光荣榜还是真香榜，这将取决于你对2019有多么痛彻心扉的领悟。 对于我来说，2019对我来说是自我革命和踏实的一年。通过我的努力和坚持，不管是工作、生活还是成长都有不错的改变，让我从一个焦虑、消极、不自信的社会人转变成一个情绪稳定、健康阳光、目标清晰的社会人。 你可能会产生一些疑问：我身处什么困境要决绝的去自我改变？ ","date":"2020-01-01","objectID":"/summary2019/:1:0","tags":null,"title":"2019年度总结：养成习惯，快速成长","uri":"/summary2019/"},{"categories":["成长日记"],"content":"02、现状 还记得2018年大学毕业的时候，角色从学生转变成社会人，地点从长春变成北京，熟悉的街道也从去图书馆的路变成著名的后场村路。 我怀揣着技术梦想准备大干一场，原本以为那灌入脑子的设计模式会被我运用到淋漓尽致，会亲身体验扛高并发和大数据的场景，可事实是每天手持扳手拧着螺丝，只是在原本自己发誓说绝不可能写出这么垃圾的代码，最后还是向现实妥协，仅仅在原来像shit一样的代码上添了一点佐料，真香！ 画外音：理想是丰满的，现实是骨感的，成本大于一切。 于是，我开始怀疑的问自己，这样下去我是不是就废了？我开始焦虑和迷失方向，找不到前行的路，想去努力都不知道力气往什么地方使。 为了内心能安心一点，我关注了超级多的技术公众号，每天白天或晚上勤恳的刷着各种技术公众号，快速浏览着技术内容，同时动作娴熟的点了收藏+在看，放佛自己能学到很多知识，事实是大多数文章只是垃圾内容，远不如看本技术书或读下英文源码来的痛快，仅仅是假装很努力欺骗自己罢了。 那段时间，除了正常上下班，每天刷着信息流，宅在出租屋，不出去玩，也不运动，更别说社交生活了。除了无所事事的刷着手机，不看剧不聊天也不玩游戏，就这样一步一步被推荐内容吞噬却自己并没有任何成长，最终陷入无限自责且不能迈出步伐去改变现状。 ","date":"2020-01-01","objectID":"/summary2019/:2:0","tags":null,"title":"2019年度总结：养成习惯，快速成长","uri":"/summary2019/"},{"categories":["成长日记"],"content":"03、落地 历经半年的折磨，我开始痛定思痛决定改变自己。那是临近2019年元旦的一天，那晚的路灯很亮，我熬夜写2019年规划到很晚，直到我在公众号发送文章「2019年，打脸式新年快乐」的时候，我的脸上洋溢出无尽的幸福感，那晚睡的无比踏实和极具安全感。 我给自己设立了3个目标囊工作、学习、生活三个纬度，那你可能会好奇我设定目标的背后逻辑是什么呢？ 目标1: 成为自律自驱的人 首次，最重要的点是信息流的泛滥成灾，让我每天花费到手机上的时间长达6小时，直接让我每天的时间被偷偷侵蚀而陷入无尽的忏悔。于是，我取关了一半以上的微信公众号，卸载了微博和脉脉，不再追热点和八卦，行动起来把时间专注在养成微习惯如阅读、运动、睡眠。 这一年，为了能够完成我的承诺，很多时候的微运动都是在晚上9点下班后，拖着疲惫不堪的身体下完成的，还好我坚持下来了。从此，甩掉了小肚囊拥有小腹肌，再也不怕游泳脱衣了。 目标2: 在技术领域有精通专长，认知水平有突破 其次，在大环境的烘托下，互联网和自媒体圈都被高薪、速成、人脉等字眼点燃，大多数人开始浮躁和找技巧，却忽视了踏实做事提升自己能力的重要性。殊不知，对于刚毕业不久的社会人，升职加薪才是你快速最有效的捷径。 还有，我不再去抱怨工作的问题如代码或沟通交流，永远那心思聚焦到解决问题上，不抱怨少生气。这一年，我花了很多时间去做代码优化和码重构，带来的回报的也极其明显，调薪2次晋升1次，从码农小生晋升成高级研发工程师。这对于大多数lowT来说，这并不是一件多么困难的事情，但对于我来说却是努力付出的褒奖。总之，我永远相信只要你把事情做到极致，时刻做好接受挑战的准备，当机会来临时你才就会顺理成章被眷顾。 当然，我还会课余时间去维护自己的公众号，输出我日常思考的内容，让我能够更深度思考问题。更值得开心的是，我认真写的两篇文章都得到了「码农翻身」刘欣老师的转载和读者的喜欢，同时给了很高的评价，让我更相信我持续输出的道路正确性。 或许，这不会短期内就收效明显，但坚持写深度思考的内容一定会给我带来意想不到的收获。 目标3: 培养兴趣爱好，平衡生活，不all in 学习 最后，培养兴趣爱好和平衡生活这个目标是最让我兴奋和开心的，它让我忧郁少了笑容多了，人也阳光灿烂多了，不再是常年呆出租屋死宅了。 庆幸的是，在百度认识了一群志同道合的朋友，一起去游泳、露营、滑雪、聚餐、看球赛，有说不完的话聊不完的梗。或许，这就是我最满足的社交状态，既开心又放松还有额外的启发，让我找到了我想要的社交模样不管是友情还是爱情。 就这样，这一年我学会了拍照+剪辑视频，学会了游泳+滑雪，还考完了折腾我已久的驾照，让我从此在记录和享受生活的路上越走越远。 当然，让我最最最最开心的是，带我外公游玩了4天北京城，去了天安门故宫长城，给他换了一身新装。看着他洋溢的笑容，第一次望北京的眼神，我心里真的无法再挑出更好的字眼来描述这场景。总之，这事很值得且意义非凡。 ","date":"2020-01-01","objectID":"/summary2019/:3:0","tags":null,"title":"2019年度总结：养成习惯，快速成长","uri":"/summary2019/"},{"categories":["成长日记"],"content":"04、总结 2019，以这样一篇简短的总结告别，我觉得这种方式带给我极大的踏实感和安全感。至少，有一天我往回看的时候，我能够对自己说我曾经来过，不后悔。 希望看到文章的你，能够从我遇到的问题和应对策略上找到一点点启发。也请你一定相信，遇到问题不可怕，关键在于你是否把思考花在解决问题上，是否有破釜沉舟改变自己的魄力，只要你认真行动而不是假装努力，回报真的永远不会缺席。 ","date":"2020-01-01","objectID":"/summary2019/:4:0","tags":null,"title":"2019年度总结：养成习惯，快速成长","uri":"/summary2019/"},{"categories":["成长日记"],"content":"1、问题 经常有些读者问我一些指导性的问题，让我冷不丁去回答，给出建议都是碎片化的，无法形成有效可落地的建议。 举个例子 我学习什么能进入优秀的互联网公司工作？ 我现在大X，我想做软件研发我应该学习什么？ 众所周知，这问题就像你问学霸说你这么厉害一样让人难以回答。我作为一个资质和背景平凡的软工本科学生，经过大学自己摸索和不断试错，毕业开始在百度从事研发工作。其实，我当时也有很多类似的疑惑，在这里给大家讲讲我的踩坑历程。 记忆中，我当年逛知乎、求助高人、甚至我的导师，都无法给出一个可执行的建议。除此之外，在我那种普通的双非学校，知名企业都不会去咱学校校招，我和学长们对春秋招的概念微乎其微，进大厂是件很困难的事情，概率与踩狗屎不相上下。 作为探路者，求助知乎和论坛，给出的结论几乎都是好好学习数据结构/算法、现在大数据很火你应该学学Hadoop/Spark、你要是会微服务、docker、k8s一定会很加分。 让我想起了我当年问学霸考试题目如何解？学霸说：这个题目是来源于第X章第X例题，你这样解，答案就出来了，很容易的。至于为什么他能想到，鬼也不知道。 当时，我真的是花里胡哨的啥都学，啥都去倒腾，不知道是不是梁静茹给我的勇气。前端、后端技术栈、Hadoop/Spark、docker/k8s这些几乎都实操过，只是很多只是入门并没有深入研究，效果自然也十分有限。 这些概念，对于小白或者在校生来说，这仿佛在对说你不用学了，除非你天生技术欲望特别强烈。这对于大多数普通人来说，明显是劝退的节奏，可操行十分有限，几乎没有参考价值，不知道从何下手。 其实，道理是没有错的，多研究底层和热门技术栈是有益的。但是，脱离实际情况谈技术就是扯犊子，就像让中国男足拿世界杯冠军显然不符合实际，更应该是根据实际情况，做产出最大的事情，否则会信心全无。 接下来，我系统性拆分问题，在不同阶段应该「学什么」、「如何学」、「学到什么程度」，重点讲我当时遇到的问题，还有我是如何去思考的，最终如何解决的，思路比结论重要。 ","date":"2019-12-05","objectID":"/university-plan/:1:0","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"2、思路 首先，说说在大厂工作都是些什么样的人，他们当年都是背着什么光环混进去的？经过我的调研和分析，主要有如下五点指标。 举个例子 学历/专业、扎实专业基本功 有成果的科研经历 省/国家级软件设计大赛 丰富互联网公司实习经历 小有名气的开源项目经历 大概思路就是，要么你证明你令人信服的天赋如逻辑系统思维、聪明，让人觉得你可以被快速培养；要么你有丰富的工程实战经验，证明你具备优秀工程师的潜质。 当然，你可能会说这么多要求，恐怕神仙也做不到啊，简直太苛刻了。在这里，我想说的是并不是上述所有指标全部满足，只是满足其中2-3项能证明你的实力即可，毕竟面试时间十分有限必须有点让人信服的东西啊。 举个例子 假设你是上海交大、华中科大大学毕业的学生，你可能重点复习数据结构算法/计算机基础等专业知识，辅之把学校的科研经历着重阐述一下。可能进入什么腾讯阿里华为百度难度也不是很大，专业知识对于你们来说自己不再话下，毕竟这些都是你们的专长。 假如你是双非大学毕业的学生，那么你必须用国家级大赛、开源项目、互联网公司实习经历证明自己。总之，多做项目，专注于技术本身，让自己更早具备职业软件工程师的实战技能。 简而言之，你没有光环，那就比别人多努力点，提前做好职业规划，把时间投入技术本身不要投机取巧。 ","date":"2019-12-05","objectID":"/university-plan/:2:0","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"3、落地 鉴于上述分析，我们知道了需求是什么？对我们来说，应把精力重点投入到技术本身、精益求精。这时候，我们将遇到一系列问题。 我应该做什么方向？（方向） 我应该学习什么内容？（规划） 我如何学这些内容？（方法/策略） 我应该学到什么程度？（量化） 如何把理论用到实际项目/产品中？（产出） ","date":"2019-12-05","objectID":"/university-plan/:3:0","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"3.1、方向\u0026规划 不同方向，意味着不同领域不同，学习的知识和实战项目有共性也有差异。在这里，我主要讲一下通用的思路。重点拿我擅长方向举例，其他方向可按照同样思路举一反三。 根据我的经验，可将内容分为原理、应用、擅长方向三个纬度。原理和应用纬度必须学习，方向纬度根据自己擅长方向深入学习。 原理：计算机网络、操作系统、数据结构/算法，这些东西都是专业课好好学即可，数据结构/算法日常多刷刷题，大不可必研究特么深入，待校招前留出时间来重点突击和复习即可。 应用：它是最基础的内容，不管你从事什么领域都将离不开它们。这也是小白入门重点花费时间的地方，你将在这里不断与程序斗争如调试、验证、异常、解决。 方向：不同方向本质上就是在基础应用上扩充，发挥它们擅长领域和特性去解决特定问题。 举个例子 后端开发方向：数据库、缓存、消息队列、rpc、微服务 大数据开发方向：Hadoop、Spark、Storm、Flink 自动化运维方向：elk、ansible、zabbix、docker、k8s ","date":"2019-12-05","objectID":"/university-plan/:3:1","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"3.2、方法\u0026量化 基于上述分析，主要讲了整体思路，大家可能会觉得有点不太好理解。接下来，拿我当时遭遇的处境进行举例阐述，这样让不同水平或时期的同学有不一样的体会。 假设回到大学时代，我会先战略性放弃计算机组成原理、操作系统原理、计算机网络等原理课，只需上课硬着头皮听个大概脑子留个印象即可，毕竟我这种全是高大上的原理，每次上课就想睡觉。当然，数据结构/算法我还能好好听听，毕竟我数学功底还行让我不排斥。事实上，我当时就是这么做的。 为什么不先深入研究计算机基础原理？ 假设你学骑自行车，你是直接上去就蹬？还是先把轮子拆下来研究清楚原理再去学习怎么蹬？根据我的经历，在新手阶段不管是接触新的语言，还是新的方向。最快的方式就是先把自行车蹬起来，等你蹬熟练了再去研究轮子是怎么造出来的。 根据上述策略，刨除我踩的一些坑，我把学习征途划分四个阶段，最终实现学习效率的最优解。 3.2.1、第一阶段：新手入门 在我入门的时候，我遇到的最大困难是代码不会写，DEBUG不会做，程序报错不会看毫无头绪，甚至大家常说的百度一下的关键字我也不知道搜。 这时候，最大的目标就是根据百度/查文档/看视频，把程序调试出预期结果，甚至你抄代码都行，很多时候抄代码你都不一定能DEBUG出预期结果。这就是现实，主要就是要把对编程的排斥消磨殆尽。 这个阶段，不需要太关注底层实现原理，最重要的工作就是把应用层面的技术，不断练习直到熟练掌握上面提到的应用纬度「 编程语言、Linux、数据库、HTTP网络协议 」。 目标：会调试、会查文档、会用搜索引擎 内容：JAVA基础语法、MYSQL数据库、Linux操作系统、HTTP通信协议 方法：只关注如何使用技术，难以理解的背下来，不关注底层原理。 成果：实现常见的管理系统模块，能部署在服务器上，供他人访问。 对于现已从事计算机行业的同学，其实这部分内容非常简单，可能按照正常水平少则几天，多则不超过一周就能开发出简单模块。简单说，它顶多是毕设设计水准，主要是让新手在感官上体验软件产品。本质上，在计算机世界里，抽象来看就是数据的计算、传输、存储。随着你的经验增多，你会发现很多技术都是诞生或优化性能都是在解决计算、存储、传输的问题。 在这里，主要让大家在系统的角度感受最简单、最初级的技术模型。 Linux操作系统：承载应用程序、数据库的运行，提供CPU供应用程序计算。 应用程序（Java/Python/Php）：JAVA主要采用Servlet、JDBC承载网络的传输、数据库连接管理。 数据库（MySQL）：主要理解关系类数据库的存储，对数据进行操作。 HTTP/TCP：熟悉重点网络协议，它分为包头/包体进行传输，包体格式可能分为form、json、pb、二进制。 3.2.2、第二阶段：项目练习 通过第一个阶段学习，你对编程从一无所知到有所斩获，对计算机世界充满了好奇，甚至有所开心。这时候，你最应该做的就是去满足你装逼的梦想。 假设你是爬虫方向，你应该去爬表情包、爬知乎数据、自动抢票，去满足你无数个装逼梦想。 假设你是算法方向，你可以去研究推荐算法、图像识别模型，去做个商品推荐、人脸识秀一秀。 假设你是后端方向，你可以去研究下网络编程/网站开发开发个仿微信聊天应用，体验下lowB版微信。 作为大学生，实验室、软件设计比赛、开源社区都是你发挥现象力的天堂，这些倒腾的经历将是你毕业时最宝贵的经历。 3.2.3、第三阶段：强化理论 经过前两个阶段实践，这时候你的软件开发水平已达到计算机毕设水平。同时，专业课如数据结构/操作系统/计算机网络也学的差不多了，对概念多多少少有初步了解。 这时候，你会发现很多原理你不懂，将很难更上一层楼。 你不知道使用ArrayList还是LinkedList？ 你不知道为什么要使用线程池？ MySQL底层原理是什么样的？ 你一直停留在写代码一时爽，一直写一直爽，从不考虑性能或规范，遇到难题就束手无策、程序直接土崩瓦解。所以，你不得不去学习理论知识让你走得更远。 问题：为什么在这个阶段强化理论知识？ 在新手阶段去强化理论知识，会让你兴趣骤减且产生学了有何用的错觉。同时，这是最好的时机，学校专业课学完你有基础概念，你有实际软件应用场景，这些东西让你深挖理论的时候会快速给你构建起基础图谱，让你兴趣激增不断体验学会的东西，将戳痛你最痛的神经，瞬间把你以前遇到的问题有新的认知，这就是答案。简单说，面向问题，解决问题，让你实实在在感受到成长，这就是成就感的力量。 问题：如何高效的学习理论？ 其实，编程语言和计算机基础都是相通的，只要你学透一门编程语言剩下的就大同小异。当然，计算机基础毕竟是枯燥无味的，学习毕竟是有方法的。站在编程语言角度，不管你用的是什么编程语言，你会发现不管什么编程语言，变来变去都是换了个花样在谈以下内容。 程序结构（数据类型、控制语句、面对对象、异常处理） 集合（list、set、map） 网络编程（IO、BIO、NIO） 并发编程（线程池） 内存管理（jvm） 不管在面试还是技术探讨，重点考察的都是集合、网络通信、线程/线程池。源自于它跟计算机基础有紧密结合，你要优化它们你必须具备扎实基本功。基于我的研究经验，我建议大家在学习计算机基础的时候，不要因为理论而理论。你应该去通过编程语言源码去学习计算机基础，只学你当前认为最重要的。 举个例子： 当我去学习数据结构/算法的时候，我会一边学习源码一边思考数据结构，这样就让我有实际应用场景不会因为理论而理论。我学习list、set源码的时候，我就学会链表、栈。我学习map的时候，我就学会了红黑树、散列表。 当我去学习计算机网络的时候，我会一边学习socket的用法，学习Linux网络通信模型epoll，这样就重点把网络协议学会了。同时，很多应用场景极少的理论知识，我就粗略记忆或者跳过，这样就节约了很多时间。 当我去学习线程/线程池的时候，我会学习锁机制、生产者/消费者模型这些操作系统原理的重要知识，跟编程语言中关联不大的我就粗略记忆。 3.2.4、第四阶段：深究专长 经过前面三个阶段的学习，你已经具备扎实基本功和项目实战经验。接下来，你需要做的就是更加的专业化，研究一些有生产意义的东西。如果你一直写学生管理系统，这些没有价值没有意义的东西，那么毫无意义。 这时候，你应该去互联网公司验证你学习的技能。除此之外，你可以去学习额外的成熟先进技术栈。这样，你就有实际业务经验，就有技术的宽度，同时又有深度，这就是你核心优势，毕竟算法/数据结构这些东西在竞争的时候大家都会。 画外音：去实习，最好去大厂实习，接受互联网软件开发的挑战。要是不能，那么去研究实际企业技术栈的应用与底层研究。 举个例子： 假设你是后端开发，你就可以去学习微服务的技术栈，springboot、dubbo、docker、hadoop都可以去学习。除此之外，设计模式，redis原理都可以去学习研究，只有这样当你去面试的时候，你有很多话题和故事讲给别人听，你的专长研究既可以让你说业务场景，你又可以讲底层原理，对答如流。 ","date":"2019-12-05","objectID":"/university-plan/:3:2","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"4、成果 经过上面的训练，已经具备了解决问题、快速学习、编写代码能力，也就是具备软件工程师的职业素养和扎实基本功。 这时候，进入互联网公司开启职业道路，你将会很快有产出，不会陷入徘徊自闭的状态。更何况，你的职业素养已经能够让你遇到问题，能快速的学习克服困难。但是，要是让你去参加面试可不一定能独善其身，毕竟工作拧螺丝，面试造火箭可不能疏忽大意。 接下来，重点讲一下如何应对面试？ 面试也就是把自己卖出去，让别人觉得你值。简历是至关重要的环节，所有的知识和技能全都是围绕它展开，否则毫无意义。因为在面试中，面试官关心你有什么，也就是面试完全围绕着你会的东西展开提问，所以你就把你的优势发挥到极致就行。 ","date":"2019-12-05","objectID":"/university-plan/:4:0","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"4.1、准备简历 简历一定要认真对待，一定要简介精炼，尽可能把内容压缩到一页，毕竟简历筛选就30秒不到。这时候，简历排版、简历字体、简历模板都有讲究，细节决定成败。 在写简历的时候，主要分为个人资料、实习经历、项目经历、专业技能。其实，没什么技巧，参考STAR原则，重点体现你在项目中的价值和思考。 要体现做了什么事情？ 遇到什么困难？ 怎么解决的？ 产出是什么？ ","date":"2019-12-05","objectID":"/university-plan/:4:1","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"4.2、梳理知识体系 以前，学习知识是零散的，学习策略更多是面向解决问题，以至于知识不系统，表达逻辑层次有限。面试官逻辑思维强，所以你必须做好充足准备才能脱颖而出。 最好的策略就是梳理知识体系和准备面经，我们都知道要是你面试官问的问题是你刚好熟悉的问题，你岂不是轻松闯关成功？所以，准备考纲、梳理知识体系、疯狂刷题这就是最好的策略。 ","date":"2019-12-05","objectID":"/university-plan/:4:2","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"},{"categories":["成长日记"],"content":"4.3、技术面试 按照互联网面试流程大多数分为三轮面。 一轮面试：主要是考察计算机基础知识和擅长语言基础知识，重点考察数据结构/算法、网络编程、擅长语言基础。但是，绝对不是死记硬背的东西，一定是深度和广度紧密结合，环环相扣直到把你肚子里的东西全部挖出来。 举个例子 获取链表倒数第N个节点的值，只许遍历一次。 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M，返回频数最高的100个词。 谈谈HashMap，说下它们的数据结构？ Key在HashCode取余以后，它可能全部堆积在某几个Key对应的链表上，这样就会造成该数据结构存储或者查询低效，那怎么解决呢？ 为什么会链表要变成红黑树，什么时候从链表变成红黑树，什么时候从红黑树变回链表？ 假设多个线程并发访问，那可能造成容器更新或者操作出现问题？ 除了使用synchronized加同步锁，还有没有其他办法解决呢？ 为什么采用CAS，能说一下ConcurrentHashMap的具体实现吗？ 你会发现每个问题都是环环相扣，从简单到难，目的就是挖掘出你的极限。大多数情况都是，从数据结构/算法入手，扩展到编程语言特性，再扩展到并发/网络编程不断进行深挖。当直接问实际用法应试者答不出来的时候，就会再次引入到计算机基础知识，这样不断反复调度试探应试者的是深度和广度。 二轮面试：这轮考察实习/项目经历，重点考察你的面试储备。众所周知，大部分应届生项目经验十分有限，大多数是图书馆管理系统、电商系统这样。重点说一下应对策略，可以去网上找你做的项目可能遇到的领域难题，去找解决办法，最终扩展补充到你的项目中。 三轮面试：这轮面试更多是经理考察应试者的基础能力。也就是逻辑思维、抗压、时间管理等基础能力，看下是否能融入团队，毕竟适合团队的才是最好的。 总之，作为普通学校的同学，你只有花更加多的时间在项目实战中，实习/打比赛/逛开源社区，这些时间让你更快接近成为职业软件工程师。当机会来临的时候，你抓住机会就踏入大厂的大门了，幸运永远不会无缘无故眷顾你。 ","date":"2019-12-05","objectID":"/university-plan/:4:3","tags":null,"title":"大学四年，如何成为还算不错的程序员？","uri":"/university-plan/"}]